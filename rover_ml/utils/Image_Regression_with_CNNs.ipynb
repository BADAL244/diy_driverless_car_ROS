{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Regression with CNNs.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wilselby/diy_driverless_car_ROS/blob/rc-ml/rover_ml/utils/Image_Regression_with_CNNs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "7vy5iiwR19nJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Environment Setup\n",
        "\n",
        "## Confirm TensorFlow can see the GPU \n",
        "\n",
        "Simply select \"GPU\" in the Accelerator drop-down in Notebook Settings (either through the Edit menu or the command palette at cmd/ctrl-shift-P)."
      ]
    },
    {
      "metadata": {
        "id": "_0h6Afcy2E9l",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NI-UBX3-2WCU",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Google Drive"
      ]
    },
    {
      "metadata": {
        "id": "LnbgHIgn2XsB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Load the Drive helper and mount\n",
        "from google.colab import drive\n",
        "\n",
        "# This will prompt for authorization.\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lZbZCuOD2JLH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "metadata": {
        "id": "AqUpKnu52L5S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import csv\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "tf.logging.set_verbosity(tf.logging.ERROR)\n",
        "\n",
        "from keras import backend as K\n",
        "from keras.models import Model, Sequential\n",
        "from keras.layers import Dense, GlobalAveragePooling2D, MaxPooling2D, Lambda, Cropping2D\n",
        "from keras.layers.convolutional import Convolution2D\n",
        "from keras.layers.core import Flatten, Dense, Dropout, SpatialDropout2D\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "\n",
        "# Improve progress bar display\n",
        "import tqdm\n",
        "import tqdm.auto\n",
        "tqdm.tqdm = tqdm.auto.tqdm\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-rEBDAIHHWTD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "iKdshk3PRvMe",
        "colab_type": "code",
        "outputId": "167d308d-53fa-4b42-8fdd-2a0ca204e17b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "# Launch Tensorboard\n",
        "# TODO https://www.tensorflow.org/tensorboard/r2/get_started\n",
        "\n",
        "from tensorboardcolab import *\n",
        "\n",
        "tbc = TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wait for 8 seconds...\n",
            "TensorBoard link:\n",
            "http://169f8933.ngrok.io\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H2sPUxOR3FlN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "metadata": {
        "id": "8YsJN12w3aug",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Extract Dataset"
      ]
    },
    {
      "metadata": {
        "id": "ndnCqXG-3I7R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "path = '/content/drive/My Drive/research/diy_driverless_car_ROS/rover_ml/output'\n",
        "data_set = 'conde_gazebo'\n",
        "tar_file = data_set + \".tar.gz\"\n",
        "\n",
        "os.chdir(path)\n",
        "\n",
        "# Unzip the .tgz file\n",
        "# x for extract\n",
        "# -v for verbose \n",
        "# -z for gnuzip\n",
        "# -f for file (should come at last just before file name)\n",
        "# -C to extract the zipped contents to a different directory\n",
        "!if [ -d $data_set ]; then echo 'Directory Exists'; else tar -xvzf $tar_file ; fi\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9FogCRzr3sUF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Parse CSV File"
      ]
    },
    {
      "metadata": {
        "id": "KeQ8c-9s3v8y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define path to csv file\n",
        "csv_path = data_set + '/interpolated.csv'\n",
        "\n",
        "# Load the CSV file into a pandas dataframe\n",
        "df = pd.read_csv(csv_path, sep=\",\")\n",
        "\n",
        "# Print the dimensions\n",
        "print(\"Dataset Dimensions:\")\n",
        "print(df.shape)\n",
        "\n",
        "# Print the first 5 lines of the dataframe for review\n",
        "print(\"\\nDataset Summary:\")\n",
        "df.head(5)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3BnBpo6-F2oR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Clean and Pre-process the Dataset"
      ]
    },
    {
      "metadata": {
        "id": "ub8CkShSJEkV",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Remove Unneccessary Columns"
      ]
    },
    {
      "metadata": {
        "id": "PDth_K-3JINP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Remove 'index' and 'frame_id' columns \n",
        "df.drop(['index','frame_id'],axis=1,inplace=True)\n",
        "\n",
        "# Verify new dataframe dimensions\n",
        "print(\"Dataset Dimensions:\")\n",
        "print(df.shape)\n",
        "\n",
        "# Print the first 5 lines of the new dataframe for review\n",
        "print(\"\\nDataset Summary:\")\n",
        "print(df.head(5))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o-zof8fUDz2C",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Detect Missing Data"
      ]
    },
    {
      "metadata": {
        "id": "ffOXGmmQD2om",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Detect Missing Values\n",
        "print(\"Any Missing Values?: {}\".format(df.isnull().values.any()))\n",
        "\n",
        "# Total Sum\n",
        "print(\"\\nTotal Number of Missing Values: {}\".format(df.isnull().sum().sum()))\n",
        "\n",
        "# Sum Per Column\n",
        "print(\"\\nTotal Number of Missing Values per Column:\")\n",
        "print(df.isnull().sum())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cKBJ4sODIFOC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Remove Zero Throttle Values"
      ]
    },
    {
      "metadata": {
        "id": "QAk-fsbkIJrh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Determine if any throttle values are zeroes\n",
        "print(\"Any 0 throttle values?: {}\".format(df['speed'].eq(0).any()))\n",
        "\n",
        "# Determine number of 0 throttle values:\n",
        "print(\"\\nNumber of 0 throttle values: {}\".format(df['speed'].eq(0).sum()))\n",
        "\n",
        "# Remove rows with 0 throttle values\n",
        "if df['speed'].eq(0).any():\n",
        "  df = df.query('speed != 0')\n",
        "  \n",
        "  # Reset the index\n",
        "  df.reset_index(inplace=True)\n",
        "  \n",
        "# Verify new dataframe dimensions\n",
        "print(\"\\nNew Dataset Dimensions:\")\n",
        "print(df.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6XZJLwqKCbE7",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## View Label Statistics"
      ]
    },
    {
      "metadata": {
        "id": "AgOG94fnCeDB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Steering Command Statistics\n",
        "print(\"\\nSteering Command Statistics:\")\n",
        "print(df['angle'].describe())\n",
        "\n",
        "print(\"\\nThrottle Command Statistics:\")\n",
        "# Throttle Command Statistics\n",
        "print(df['speed'].describe())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nae5TmmFFJ5T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## View Histogram of Steering Commands"
      ]
    },
    {
      "metadata": {
        "id": "JvPMKVGfFNdy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_bins = 25\n",
        "hist, bins = np.histogram(df['angle'], num_bins)\n",
        "print(bins)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Bh3DSasZQKCi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "num_bins = 25\n",
        "samples_per_bin = 50\n",
        "hist, bins = np.histogram(df['angle'], num_bins)\n",
        "center = (bins[:-1]+ bins[1:]) * 0.5\n",
        "plt.bar(center, hist, width=0.05)\n",
        "plt.plot((np.min(df['angle']), np.max(df['angle'])), (samples_per_bin, samples_per_bin))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cwunrGrDQweC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Normalize the histogram\n",
        "#print('total data:', len(df))\n",
        "#remove_list = []\n",
        "#for j in range(num_bins):\n",
        "#  list_ = []\n",
        "#  for i in range(len(df['angle'])):\n",
        "#    if df.loc[i,'angle'] >= bins[j] and df.loc[i,'angle'] <= bins[j+1]:\n",
        "#      list_.append(i)\n",
        "#  list_ = shuffle(list_)\n",
        "#  list_ = list_[samples_per_bin:]\n",
        "#  remove_list.extend(list_)\n",
        " \n",
        "#print('removed:', len(remove_list))\n",
        "#data.drop(data.index[remove_list], inplace=True)\n",
        "#print('remaining:', len(data))\n",
        " \n",
        "#hist, _ = np.histogram(data['steering'], (num_bins))\n",
        "#plt.bar(center, hist, width=0.05)\n",
        "#plt.plot((np.min(data['steering']), np.max(data['steering'])), (samples_per_bin, samples_per_bin))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jg1aMw8mGQ8o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Load the Images"
      ]
    },
    {
      "metadata": {
        "id": "xkmkVIiKGStZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define image loading function\n",
        "def load_images(dataframe):\n",
        "  \n",
        "  # initialize images array\n",
        "  images = []\n",
        "  \n",
        "  for i in df.index.values:\n",
        "    name = path + '/' + data_set + '/' + dataframe.loc[i,'filename'] \n",
        "    center_image = cv2.imread(name)\n",
        "    center_image = cv2.resize(center_image, (320,180))\n",
        "    images.append(center_image)\n",
        "    \n",
        "  return np.array(images)\n",
        "  \n",
        "# Load images   \n",
        "images = load_images(df) \n",
        "\n",
        "# Normalize image values\n",
        "images = images / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1uqfxZ4uGoNX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## View a Sample Image"
      ]
    },
    {
      "metadata": {
        "id": "L2nwHnC4Gq1m",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# View a Single Image \n",
        "img_name = path + '/' + data_set + '/' + df.loc[0,'filename']\n",
        "print(img_name)\n",
        "center_image = cv2.imread(img_name)\n",
        "center_image_mod = cv2.resize(center_image, (320,180)) #resize from 720x1280 to 180x320\n",
        "plt.imshow(center_image_mod)\n",
        "plt.grid(False)\n",
        "plt.show() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gTQywtOyGvLv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## View Multiple Images"
      ]
    },
    {
      "metadata": {
        "id": "ODmdWWpsGxK2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Number of Images to Display\n",
        "num_images = 4\n",
        "\n",
        "# Display the images\n",
        "i = 0\n",
        "for i in range (0,num_images):\n",
        "    image_path = df.loc[i,'filename']\n",
        "    angle = df.loc[i,'angle']\n",
        "    img_name = path + '/' + data_set + '/' + image_path\n",
        "    image = cv2.imread(img_name)\n",
        "    image = cv2.resize(image, (320,180))\n",
        "    plt.subplot(num_images/2,num_images/2,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(image, cmap=plt.cm.binary)\n",
        "    plt.xlabel('angle: {:.2}'.format(angle))\n",
        "    i += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BgFvPAZl9vfP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Split the Dataset"
      ]
    },
    {
      "metadata": {
        "id": "t2ibXOio_saZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the feature set"
      ]
    },
    {
      "metadata": {
        "id": "Up2wjjIt-B1a",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# partition the data into training and testing splits using 75% of\n",
        "# the data for training and the remaining 25% for testing\n",
        "split = train_test_split(df, images, test_size=0.25, random_state=42)\n",
        "(trainAttrX, testAttrX, trainImagesX, testImagesX) = split\n",
        "\n",
        "print(\"Number of training samples: {}\".format(trainAttrX.shape[0]))\n",
        "print(\"Number of validation samples: {}\".format(testAttrX.shape[0]))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dSHgIhOy_Cxd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Create the label set"
      ]
    },
    {
      "metadata": {
        "id": "OMbWR4YW_Oe2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trainY = trainAttrX[\"angle\"] \n",
        "testY = testAttrX[\"angle\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "m3t9Inb5G7lp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define a Batch Generator"
      ]
    },
    {
      "metadata": {
        "id": "qh3kRBYuG9ed",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def csv_image_generator(dataframe, batch_size, mode=\"train\", aug=None):\n",
        "  \n",
        "  num_samples = dataframe.shape[0]\n",
        "  \n",
        "  # loop indefinitely\n",
        "  while True:\n",
        "    \n",
        "    for offset in range(0, num_samples, batch_size):\n",
        "      batch_samples = dataframe[offset:offset+batch_size]\n",
        "    \n",
        "      # initialize our batches of images and labels\n",
        "      #print(\"\\nLoaded batch {0}\\n\".format(1+(offset/batch_size)))\n",
        "      images = []\n",
        "      print(\"Init {}\".format(type(images)))\n",
        "      labels = []\n",
        "      index = 0\n",
        "      \n",
        "      for index in range(0,batch_samples.shape[0]):\n",
        "        if batch_samples.loc[offset,'filename'] != \"filename\":\n",
        "    \n",
        "          name = path + '/' + data_set + '/' + dataframe.loc[offset,'filename']\n",
        "          center_image = cv2.imread(name)\n",
        "          center_image = cv2.resize(center_image, (320,180))\n",
        "          label = dataframe.loc[offset,'angle']\n",
        "          print(\"Loop {}\".format(type(images)))\n",
        "          images.append(center_image)\n",
        "          labels.append(label)\n",
        "          \n",
        "          index += 1\n",
        "      \n",
        "          # if the data augmentation object is not None, apply it\n",
        "          if aug is not None:\n",
        "            (images, labels) = next(aug.flow(np.array(images), labels, batch_size=batch_size))\n",
        "          print(\"Aug {}\".format(type(images)))\n",
        " \n",
        "      # yield the batch to the calling function\n",
        "      yield (np.array(images), labels)\n",
        "        \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PAVmOpT8HEg0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Define an Image Augmentation Data Generator"
      ]
    },
    {
      "metadata": {
        "id": "Gu67P9z2HIZV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Construct the training image generator for data augmentation\n",
        "aug = ImageDataGenerator(rotation_range=20, zoom_range=0.15,\n",
        "\twidth_shift_range=0.2, height_shift_range=0.2, shear_range=0.15,\n",
        "\tvertical_flip=True, fill_mode=\"nearest\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yA2di_mIdhvW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Initialize Data Generators"
      ]
    },
    {
      "metadata": {
        "id": "dvhng7hsdiJQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define a batch size\n",
        "batch_size = 32\n",
        "\n",
        "# initialize both the training and testing image generators\n",
        "trainGen = csv_image_generator(df, batch_size, mode=\"train\", aug=aug)\n",
        "testGen = csv_image_generator(df, batch_size, mode=\"train\", aug=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-_WW4C27_4HO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ]
    },
    {
      "metadata": {
        "id": "Xq73r642_6iI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocess the Input Image"
      ]
    },
    {
      "metadata": {
        "id": "95obLCcw_8lT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Initialize the model\n",
        "model = Sequential()\n",
        "\n",
        "# trim image to only see section with road\n",
        "# (top_crop, bottom_crop), (left_crop, right_crop)\n",
        "model.add(Cropping2D(cropping=((50,20), (0,0)), input_shape=(180,320,3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z62Wkaj4ADbB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Build the Model"
      ]
    },
    {
      "metadata": {
        "id": "AK578kaYAE1_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Nvidia model\n",
        "model.add(Convolution2D(24, (5, 5), activation=\"relu\", name=\"conv_1\", strides=(2, 2)))\n",
        "model.add(Convolution2D(36, (5, 5), activation=\"relu\", name=\"conv_2\", strides=(2, 2)))\n",
        "model.add(Convolution2D(48, (5, 5), activation=\"relu\", name=\"conv_3\", strides=(2, 2)))\n",
        "model.add(SpatialDropout2D(.5, dim_ordering='default'))\n",
        "\n",
        "model.add(Convolution2D(64, (3, 3), activation=\"relu\", name=\"conv_4\", strides=(1, 1)))\n",
        "model.add(Convolution2D(64, (3, 3), activation=\"relu\", name=\"conv_5\", strides=(1, 1)))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(1164))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(100, activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(50, activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(10, activation='relu'))\n",
        "model.add(Dropout(.5))\n",
        "model.add(Dense(1))\n",
        "\n",
        "model.compile(loss='mse', optimizer='adam', metrics=['mse','mape'])\n",
        "\n",
        "# Print model sumamry\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "USKQYVmhAMaJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup Checkpoints"
      ]
    },
    {
      "metadata": {
        "id": "BS6R3FVoAOPc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# checkpoint\n",
        "model_path = data_set + '/model'\n",
        "\n",
        "!if [ -d $model_path ]; then echo 'Directory Exists'; else mkdir $model_path; fi\n",
        "\n",
        "\n",
        "filepath = path + '/' + model_path + \"/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='auto', period=1)\n",
        "\n",
        "#model.load_weights(model_path = '/')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BVIGONgjSy7V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Setup Tensorboard"
      ]
    },
    {
      "metadata": {
        "id": "-YWTAEeyS0tw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "tbCallBack = TensorBoard(log_dir='./log', histogram_freq=1,\n",
        "                         write_graph=True,\n",
        "                         write_grads=True,\n",
        "                         batch_size=batch_size,\n",
        "                         write_images=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "71O-pWk9AQy3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training"
      ]
    },
    {
      "metadata": {
        "id": "3nkossmrAUo2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Define number of epochs\n",
        "n_epoch = 30\n",
        "\n",
        "# Define callbacks\n",
        "callbacks_list = [TensorBoardColabCallback(tbc)]\n",
        "\n",
        "# Fit the model\n",
        "#history_object = model.fit_generator(train_generator, steps_per_epoch=(len(train_samples) / batch_size_value), validation_data=validation_generator, validation_steps=(len(validation_samples)/batch_size_value), callbacks=callbacks_list, epochs=n_epoch)\n",
        "#history_object = model.fit_generator(\n",
        "#\ttrainGen,\n",
        "#\tsteps_per_epoch=trainAttrX.shape[0] // batch_size,\n",
        "#\tvalidation_data=testGen,\n",
        "#\tvalidation_steps=testAttrX.shape[0] // batch_size,\n",
        "#  callbacks=callbacks_list,\n",
        "#\tepochs=n_epoch)\n",
        "\n",
        "# Fit the model\n",
        "history_object = model.fit(trainImagesX, trainY, validation_data=(testImagesX, testY), callbacks=callbacks_list, epochs=n_epoch, batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OdaGfWNxBT4T",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Save the Model"
      ]
    },
    {
      "metadata": {
        "id": "jWE--9r4BZEk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model_path_full = path + '/' + model_path + '/'\n",
        "\n",
        "model.save(model_path_full + 'model.h5')\n",
        "with open(model_path_full + 'model.json', 'w') as output_json:\n",
        "    output_json.write(model.to_json())\n",
        "\n",
        "# Save TensorFlow model\n",
        "tf.train.write_graph(K.get_session().graph.as_graph_def(), logdir=model_path_full, name='model.pb', as_text=False)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y-pCmYO1A89_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Evaluate the Model"
      ]
    },
    {
      "metadata": {
        "id": "podNBS9cBRNW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#scores = model.evaluate(testImagesX, testY, verbose=0, batch_size=32)\n",
        "#print(\"Loss: {}\".format(scores*100))\n",
        "  \n",
        "#score = model.evaluate_generator(validation_generator, len(validation_samples)/batch_size_value,use_multiprocessing=True)\n",
        "#print(\"Loss: {:.2}\".format(score))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "caA5cztpBPTM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Compute the loss"
      ]
    },
    {
      "metadata": {
        "id": "9FpUcNFu_5z6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#TODO: Remove 0s in dataset\n",
        "\n",
        "preds = model.predict(testImagesX)\n",
        "\n",
        "\n",
        "diff = preds.flatten() - testY\n",
        "percentDiff = (diff / testY) * 100\n",
        "absPercentDiff = np.abs(percentDiff)\n",
        "\n",
        "#print(diff/testY)\n",
        "\n",
        "# compute the mean and standard deviation of the absolute percentage\n",
        "# difference\n",
        "mean = np.mean(absPercentDiff)\n",
        "std = np.std(absPercentDiff)\n",
        "print(\"[INFO] mean: {:.2f}%, std: {:.2f}%\".format(mean, std))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5jVE6WfNGDEM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot a Prediction"
      ]
    },
    {
      "metadata": {
        "id": "O7o-6SbBD9zx",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Plot the Results"
      ]
    },
    {
      "metadata": {
        "id": "t-M9fEvWD_ZJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model_path_full = path + '/' + model_path + '/'\n",
        "\n",
        "# Plot the training and validation loss for each epoch\n",
        "print('Generating loss chart...')\n",
        "plt.plot(history_object.history['loss'])\n",
        "plt.plot(history_object.history['val_loss'])\n",
        "plt.title('model mean squared error loss')\n",
        "plt.ylabel('mean squared error loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['training set', 'validation set'], loc='upper right')\n",
        "plt.savefig(model_path_full + 'model.png')\n",
        "\n",
        "# Done\n",
        "print('Done.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QMGEoYbVHnaJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# References:\n",
        "https://www.pyimagesearch.com/2019/01/28/keras-regression-and-cnns/\n",
        "https://www.pyimagesearch.com/2019/01/21/regression-with-keras/\n",
        "https://www.pyimagesearch.com/2018/12/24/how-to-use-keras-fit-and-fit_generator-a-hands-on-tutorial/\n",
        "https://colab.research.google.com/github/tensorflow/examples/blob/master/courses/udacity_intro_to_tensorflow_for_deep_learning/l04c01_image_classification_with_cnns.ipynb#scrollTo=7MqDQO0KCaWS"
      ]
    }
  ]
}